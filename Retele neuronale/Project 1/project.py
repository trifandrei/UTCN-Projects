# -*- coding: utf-8 -*-
"""Exam.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ye-IDvVHMlCrHcdMK4lLh8RtA_Nml0vu
"""

import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split 
from sklearn import metrics 
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score

#incarc dataset-ul
col_names = ['Sample code number', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', ' Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli',' Mitoses','Class']

pima = pd.read_csv("/content/breast-cancer-wisconsin .csv")


pima.columns=col_names

#setez variabilele de features si coloana de target
feature_cols = ['Sample code number', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', ' Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli',' Mitoses']
X = pima[feature_cols] 
y = pima.Class

print(pima[feature_cols])

print(pima.Class)

results = []
#vectorul in care se vor stoca toate scorurile de acuratete

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # impart datasetul in date de antrenare si test

#DecisionTree

clf = DecisionTreeClassifier(criterion="entropy",splitter="random", max_depth=5)  

clf = clf.fit(X_train,y_train)

#predict varialebles
y_pred = clf.predict(X_test)


print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

results.append(metrics.accuracy_score(y_test, y_pred))

print("MAE: ",metrics.mean_absolute_error(y_test,y_pred ))
print("MSE: ",metrics.mean_squared_error(y_test, y_pred))
print("Precision: ",precision_score(y_test, y_pred, average='macro'))
print("Recall: ",recall_score(y_test, y_pred, average='macro'))

#afisez decision tree 
from sklearn.externals.six import StringIO  
from IPython.display import Image  
from sklearn.tree import export_graphviz
import pydotplus
dot_data = StringIO()
export_graphviz(clf, out_file=dot_data,  
                filled=True, rounded=True,
                special_characters=True, feature_names = feature_cols,class_names=['0','1'])
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  
graph.write_png('Brest-Cancers.png')
Image(graph.create_png())

from sklearn.metrics import confusion_matrix 
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error

#Naive baise
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 11) 

Mnb = MultinomialNB().fit(X_train, y_train) 

Mnb_predictions = Mnb.predict(X_test) 

accuracy = Mnb.score(X_test, y_test) 

print ("Accuracy: ",accuracy) 
results.append(accuracy)


print("MAE: ",metrics.mean_absolute_error(y_test,Mnb_predictions ))
print("MSE:",metrics.mean_squared_error(y_test,Mnb_predictions ))
print("Precision: ",precision_score(y_test,Mnb_predictions, average='macro'))
print("Recall: ",recall_score(y_test,Mnb_predictions, average='macro'))

#Multilayerâ€“Perceptron


from sklearn.neural_network import MLPClassifier
from sklearn.metrics import confusion_matrix


X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1) 

classifier =  MLPClassifier(hidden_layer_sizes=(8,8,8), activation='relu', solver='adam', max_iter=100)

classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)

#adaug acuratetea in vecotr de acurateti
results.append(metrics.accuracy_score(y_test, y_pred))

#afisez acuratetea ,precizia ,recal ,erarea medie absoluta,squerd mean error
print ("Accuracy: ",metrics.accuracy_score(y_test, y_pred))
print ("MAE: ",metrics.mean_absolute_error(y_test,y_pred))
print("MSE: ",metrics.mean_squared_error(y_test,y_pred ))
print("Precision: ",precision_score(y_test,y_pred, average='macro'))
print("Recall: ",recall_score(y_test,y_pred, average='macro'))

#Random forest
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd 
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix 

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1) 

model=RandomForestClassifier(n_estimators=100,criterion='entropy',random_state=0)
model.fit(X_train,y_train)

y_predf=model.predict(X_test)

results.append(metrics.accuracy_score(y_test, y_predf))
print("Accuracy: ",metrics.accuracy_score(y_test, y_predf))
print("MAE: ",metrics.mean_absolute_error(y_test,y_predf ))
print("MSE: ",metrics.mean_squared_error(y_test,y_predf ))
print("Precision: ",precision_score(y_test,y_predf, average='macro'))
print("Recall: ",recall_score(y_test,y_predf, average='macro'))

#Ada Boost
from sklearn.ensemble import AdaBoostClassifier
from sklearn.metrics import precision_score

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1) 

classifier = AdaBoostClassifier(
    DecisionTreeClassifier(max_depth=1),
    n_estimators=200)

classifier.fit(X_train, y_train)

predictions = classifier.predict(X_test)
confusion_matrix(y_test, predictions)

print (cm)

results.append(classifier.score(X_test,y_test))
print("Accuracy: ",classifier.score(X_test,y_test))
print("MAE: ",metrics.mean_absolute_error(y_test,predictions ))
print("MSE: ",metrics.mean_squared_error(y_test,predictions))
print("Precision: ",precision_score(y_test, predictions, average='macro'))
print("Recall: ",recall_score(y_test, predictions, average='macro'))

#KNN classifier

from sklearn.model_selection import train_test_split

# impart setul de date in setrui de test si antrenare
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2) # 70% training and 30% test

from sklearn.neighbors import KNeighborsClassifier

#creez KNN
knn = KNeighborsClassifier(n_neighbors=4)

#andtrenez modelul folosind datele de train
knn.fit(X_train, y_train)

#anticipez predictiile pentru setul de test
ypredk= knn.predict(X_test)

from sklearn import metrics

results.append(knn.score(X_test,ypredk))
print("Acuracy: ",metrics.accuracy_score(y_test, ypredk))
print("MAE: ",metrics.mean_absolute_error(y_test,ypredk))
print("MSE: ",metrics.mean_squared_error(y_test,ypredk))
print("Precision: ",precision_score(y_test, ypredk, average='macro'))

#Logistic Regresion

from sklearn.model_selection import train_test_split

X_train,X_test,Y_train,Y_test=train_test_split(X,y,train_size=.75, random_state=0)

from sklearn.linear_model import LogisticRegression

logisticRegr = LogisticRegression()

logisticRegr.fit(X_train, Y_train)

predictionsl = logisticRegr.predict(X_test)


results.append(logisticRegr.score(X_test, Y_test))
print("Accuracy: ",logisticRegr.score(X_test, Y_test))
print("MAE: ",metrics.mean_absolute_error(Y_test,predictionsl))
print("MSE: ",metrics.mean_squared_error(Y_test,predictionsl))
print("Precision: ",precision_score(Y_test, predictionsl, average='macro'))
print("Recall: ",recall_score(Y_test, predictionsl, average='macro'))

#Ridge Classifier

from sklearn.model_selection import train_test_split


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=0) 

from sklearn.linear_model import RidgeClassifier

rg = RidgeClassifier().fit(X, y)

ypred2 = rg.predict(X_test)

results.append(rg.score(X_test,y_test))
print("Accuracy: ",rg.score(X_test,y_test))
print("MAE: ",metrics.mean_absolute_error(y_test,ypred2 ))
print("MSE: ",metrics.mean_squared_error(y_test,ypred2))
print("Precision: ",precision_score(y_test,ypred2, average='macro'))
print("Recall: ",recall_score(y_test,ypred2, average='macro'))

#fac diagrama cu toate acuratetile algoritmilor pentru ai putea clasifica
import matplotlib.pyplot as plt
import numpy as np



plt.rcdefaults()
fig, ax = plt.subplots()


people = ('Decision tree(J48)', 'Naive Baies','Multilayer Pereptron','Random Forest','Ada Boost','Lazy IBK(KNN)','Logistic Regresion','Ridge Classifier')
y_pos = np.arange(len(people))


ax.barh(y_pos, results,0.2, align='center',alpha=0.8)
ax.set_yticks(y_pos)
ax.set_yticklabels(people)


ax.set_title('Accuracy')




plt.show()

